{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DEEP - Assignment 1",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylerelias/T-796-DEEP-Assignment/blob/main/DEEP_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EETMIWmyKa4a"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "- Jesper Winsten\n",
        "- Stefán Rangarsson\n",
        "- Tyler Elías Jones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6Y-X8ZePhXG"
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "from os.path import join\n",
        "\n",
        "ROOT='/content/drive'\n",
        "drive.mount(ROOT)\n",
        "PROJECT='MyDrive/Colab Notebooks/Lab03'\n",
        "\n",
        "PROJECT_PATH=join(ROOT, PROJECT)\n",
        "\n",
        "!rsync -aP \"{PROJECT_PATH}\"/* ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg8IGCyfSGhZ"
      },
      "source": [
        "# Imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZt7eR7v09J4"
      },
      "source": [
        "def read_stock_prices(stocks):\n",
        "    with open('stock_prices.txt') as f:\n",
        "        for line in f:\n",
        "            fields = line.split()\n",
        "\n",
        "            year = 0\n",
        "            # Making the years into 0-2 format, put in dict later?\n",
        "            if fields[1] == \"2017\":\n",
        "                year = 0\n",
        "            if fields[1] == \"2018\":\n",
        "                year = 1\n",
        "            if fields[1] == \"2019\":\n",
        "                year = 2\n",
        "\n",
        "            record = (int(fields[0]),\n",
        "                      int(year),\n",
        "                      int(fields[2]),\n",
        "                      int(fields[3]),\n",
        "                      float(fields[4]))\n",
        "            stocks.append(record)\n",
        "\n",
        "\n",
        "def read_info(info):\n",
        "    with open('info.txt') as f:\n",
        "        for line in f:\n",
        "            fields = line.split()\n",
        "            record = (int(fields[0]),\n",
        "                      int(fields[1]),\n",
        "                      int(fields[2]),\n",
        "                      int(fields[3]),\n",
        "                      int(fields[4]),\n",
        "                      int(fields[5]),\n",
        "                      int(fields[6]),\n",
        "                      float(fields[7]),\n",
        "                      float(fields[8]),\n",
        "                      float(fields[9]),\n",
        "                      int(fields[10]),)\n",
        "            info.append(record)\n",
        "\n",
        "\n",
        "def read_segments(segments):\n",
        "    with open('market_segments.txt') as f:\n",
        "        for line in f:\n",
        "            fields = line.split()\n",
        "            record = (int(fields[0]),\n",
        "                      str(fields[1]),)\n",
        "            segments.append(record)\n",
        "\n",
        "\n",
        "def read_market_analysis(analysis):\n",
        "    with open('market_analysis.txt') as f:\n",
        "        for line in f:\n",
        "            fields = line.split()\n",
        "            record = (str(fields[0]),\n",
        "                      int(fields[1]),\n",
        "                      int(fields[2]),\n",
        "                      int(fields[3]),)\n",
        "            analysis.append(record)\n",
        "\n",
        "\n",
        "# CONSTANTS FOR COLUMN NAMES\n",
        "COMPANY_NAME = 0\n",
        "YEAR = 1\n",
        "DAY = 2\n",
        "QUARTER = 3\n",
        "STOCK_PRICE = 4\n",
        "EXPERT_1 = 5\n",
        "# EXPERT_2 index not used, skip\n",
        "SENTIMENT = 7\n",
        "M1 = 8\n",
        "M2 = 9\n",
        "M3 = 10\n",
        "M4 = 11\n",
        "SEGMENT = 12\n",
        "TREND = 13\n",
        "\n",
        "stock_prices = []\n",
        "info_array = []\n",
        "segments_array = []\n",
        "analysis_array = []\n",
        "\n",
        "combined_data = []\n",
        "\n",
        "# Store the Max value for each data\n",
        "max_stock_price = 0\n",
        "max_day = 0\n",
        "max_sentiment_analysis = 0\n",
        "max_m1 = 0\n",
        "max_m2 = 0\n",
        "\n",
        "# The target predictions for the ANN\n",
        "target_label = []\n",
        "\n",
        "# Read from the files\n",
        "read_stock_prices(stock_prices)\n",
        "read_info(info_array)\n",
        "read_segments(segments_array)\n",
        "read_market_analysis(analysis_array)\n",
        "\n",
        "# This is used to compare prev. stock price to current one\n",
        "previous = tuple()\n",
        "\n",
        "for i in range(len(stock_prices)):\n",
        "\n",
        "  ms_index = tuple() # Market segment index, instead of string\n",
        "  trend = tuple()    # Trend value, -1 to 1\n",
        "\n",
        "  if segments_array[stock_prices[i][0]][1] == 'IT':\n",
        "      ms_index = ms_index + (1,)\n",
        "      # Look up the trend value for the given segment\n",
        "      for item in analysis_array:\n",
        "          list_item = list(item)\n",
        "          if (stock_prices[i][YEAR] + 2017) == list_item[1] and \\\n",
        "                stock_prices[i][QUARTER] == list_item[2] and \\\n",
        "                list_item[0] == 'IT':\n",
        "              trend = trend + (item[3],)\n",
        "              break\n",
        "\n",
        "\n",
        "  elif segments_array[stock_prices[i][0]][1] == 'BIO':\n",
        "      ms_index = ms_index + (0,)\n",
        "      # Look up the trend value for the given segment\n",
        "      for item in analysis_array:\n",
        "          list_item = list(item)\n",
        "          if (stock_prices[i][YEAR] + 2017) == list_item[1] and \\\n",
        "                stock_prices[i][QUARTER] == list_item[2] and \\\n",
        "                list_item[0] == 'BIO':\n",
        "              trend = trend + (item[3],)\n",
        "              break\n",
        "\n",
        "  # Place all the data into a single list\n",
        "  combined_data.append(\n",
        "      stock_prices[i] +\n",
        "      info_array[i][STOCK_PRICE::] +\n",
        "      ms_index +\n",
        "      trend\n",
        "  )\n",
        "\n",
        "  # Create a lable to use for the model\n",
        "  if previous and previous[STOCK_PRICE] < stock_prices[i][STOCK_PRICE]:\n",
        "      target_label.append(1)\n",
        "  else:\n",
        "      target_label.append(0)\n",
        "\n",
        "  # See if there is a new max stock prize\n",
        "  if combined_data[i][STOCK_PRICE] > max_stock_price:\n",
        "      max_stock_price = combined_data[i][STOCK_PRICE]\n",
        "\n",
        "  if combined_data[i][DAY] > max_day:\n",
        "      max_day = combined_data[i][DAY]\n",
        "\n",
        "  if combined_data[i][SENTIMENT] > max_sentiment_analysis:\n",
        "      max_sentiment_analysis = combined_data[i][SENTIMENT]\n",
        "\n",
        "  if combined_data[i][M1] > max_m1:\n",
        "      max_m1 = combined_data[i][M1]\n",
        "\n",
        "  if combined_data[i][M2] > max_m2:\n",
        "      max_m2 = combined_data[i][M2]\n",
        "  # To compare the current stock with previous stock\n",
        "  previous = combined_data[i]\n",
        "\n",
        "# Normalize the data\n",
        "\n",
        "normalized = []\n",
        "\n",
        "for s in combined_data:\n",
        "    replace = (\n",
        "        s[COMPANY_NAME],                      # company name\n",
        "        s[YEAR],                              # year\n",
        "        s[DAY] / max_day,                     # day\n",
        "        s[QUARTER],                           # quarter\n",
        "        s[STOCK_PRICE] / max_stock_price,     # stock price\n",
        "        s[EXPERT_1],                          # expert 1\n",
        "        s[SENTIMENT] / max_sentiment_analysis,# sentiment analysis\n",
        "        s[M1] / max_m1,                       # m1\n",
        "        s[M2] / max_m2,                       # m2\n",
        "        s[M3],                                # m3\n",
        "        s[M4],                                # m4\n",
        "        s[SEGMENT],                           # market_segment, just seems to decrease accuracy\n",
        "        s[TREND],                             # trend\n",
        "\n",
        "    )\n",
        "    normalized.append(replace)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z98HQ1YhgFjY"
      },
      "source": [
        "# Read test and training data from files into a dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "BATCH_SIZE = 10 \n",
        "\n",
        "\n",
        "X, y = torch.Tensor(normalized), torch.Tensor(target_label)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True)\n",
        "\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "\n",
        "\n",
        "train_set = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_set = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZgohiLtz9AU"
      },
      "source": [
        "WIDTH = 64  # The width of the layers\n",
        "IN_FEATURES = X.shape[1]  # The amount of data coming in [x, y, z, a]\n",
        "OUT_FEATURES = 2  # Number of possible answers [0, 1]\n",
        "EPOCHS_VAL = 90\n",
        "LEARNING_RATE = 0.00515\n",
        "DROPOUT_VALUE = 0.375"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W42PgbwQPdOX"
      },
      "source": [
        "class MyANN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(DROPOUT_VALUE)\n",
        "\n",
        "        self.fc1 = nn.Linear(IN_FEATURES, WIDTH)\n",
        "        self.fc2 = nn.Linear(WIDTH, WIDTH)\n",
        "        self.fc3 = nn.Linear(WIDTH, WIDTH)\n",
        "        self.fc4 = nn.Linear(WIDTH, WIDTH)\n",
        "        self.fc5 = nn.Linear(WIDTH, OUT_FEATURES)\n",
        "        return\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.dropout(self.fc2(x)))\n",
        "        x = torch.relu(self.dropout(self.fc3(x)))\n",
        "        x = torch.relu(self.dropout(self.fc4(x)))\n",
        "        x = self.fc5(x)\n",
        "        return nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "net = MyANN()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzErScpOUhhL"
      },
      "source": [
        "## Train the network\n",
        "\n",
        "The model gives an accuracy of around 87.5 - 91.5%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQKPKC5sUf1j"
      },
      "source": [
        "losses = [] # TODO: Remove\n",
        "\n",
        "for _ in range(100):\n",
        "\n",
        "  net = MyANN()\n",
        "  optimization = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "  net.train()\n",
        "  for epochs in range(EPOCHS_VAL):\n",
        "      for data in train_set:\n",
        "          _X, _y = data\n",
        "          net.zero_grad()\n",
        "          output = net(_X)  # Forward pass\n",
        "          _y = torch.tensor(_y, dtype=torch.long)\n",
        "          loss_c = nn.CrossEntropyLoss()\n",
        "          loss = loss_c(output, _y)  # Computing\n",
        "          loss.backward()  # Back-propigation\n",
        "          optimization.step()\n",
        "      # losses.append(loss.item())\n",
        "\n",
        "  # Evaluate\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  net.eval()\n",
        "  for data in test_set:\n",
        "      _X, _y = data\n",
        "      output = net(_X)  # Forward pass\n",
        "      for idx, val in enumerate(output):\n",
        "          if torch.argmax(val) == _y[idx]:\n",
        "              correct += 1\n",
        "          total += 1\n",
        "  print(\"Accuracy: \", round(correct / total, 3))\n",
        "\n",
        "  if(round(correct / total, 3) >= 0.9): # Save all networks that give > 90% acc, muhaha\n",
        "    filename = \"network_\" + str(round(correct / total, 3)) + \".pt\"\n",
        "    print(filename)\n",
        "    torch.save(net.state_dict(), filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYmQmBbdibIk"
      },
      "source": [
        "PLOTS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nTb42p5ic0H"
      },
      "source": [
        "def plot_accuracy_loss(accuracy, losses):\n",
        "  fig, (ax1, ax2) = plt.subplots(2)\n",
        "  fig.suptitle('Accuracy and Loss')\n",
        "  ax1.plot(accuracy)\n",
        "  ax2.plot(losses)\n",
        "  ax1.set_title('Accuracy')\n",
        "  ax2.set_title('Loss')\n",
        "\n",
        "def plot_losses(losses):\n",
        "  plt.plot(losses)\n",
        "\n",
        "accura = [0.855, 0.870, 0.857, 0.900, 0.700, 0.910,0.855, 0.870, 0.857, 0.900, 0.700, 0.910,0.855, 0.870, 0.857, 0.900, 0.700, 0.910,0.855, 0.870, 0.857, 0.900, 0.700, 0.910,0.855, 0.870, 0.857, 0.900, 0.700, 0.910,0.855, 0.870, 0.857, 0.900, 0.700, 0.910,0.855, 0.870, 0.857, 0.900, 0.700, 0.910,0.855, 0.870, 0.857, 0.900, 0.700, 0.910,0.855, 0.870, 0.857, 0.900, 0.700, 0.910,0.855, 0.870, 0.857, 0.900, 0.700, 0.910]\n",
        "\n",
        "#plot_accuracy_loss(accura, losses)\n",
        "plot_losses(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHRknFXCifk4"
      },
      "source": [
        "all_days = [item[2] for item in combined_data]\n",
        "all_stock_prices = [item[4] for item in combined_data]\n",
        "all_company_names = [item[0] for item in combined_data]\n",
        "min_day = min(days)\n",
        "max_day = max(days)\n",
        "\n",
        "days_in_2017 = []\n",
        "days_in_2018 = []\n",
        "days_in_2019 = []\n",
        "stock_prices_2017 = []\n",
        "stock_prices_2018 = []\n",
        "stock_prices_2019 = []\n",
        "company_names_2017 = []\n",
        "company_names_2018 = []\n",
        "company_names_2019 = []\n",
        "\n",
        "stock_prices_2017_c0 = []\n",
        "stock_prices_2017_c1 = []\n",
        "stock_prices_2017_c2 = []\n",
        "stock_prices_2018_c0 = []\n",
        "stock_prices_2018_c1 = []\n",
        "stock_prices_2018_c2 = []\n",
        "stock_prices_2019_c0 = []\n",
        "stock_prices_2019_c1 = []\n",
        "stock_prices_2019_c2 = []\n",
        "\n",
        "for item in combined_data:\n",
        "  if item[1] == 0:\n",
        "    if item[0] == 0:\n",
        "      stock_prices_2017_c0.append(item[4])\n",
        "    if item[0] == 1:\n",
        "      stock_prices_2017_c1.append(item[4])\n",
        "    if item[0] == 2:\n",
        "      stock_prices_2017_c2.append(item[4])\n",
        "    days_in_2017.append(item[2])\n",
        "    stock_prices_2017.append(item[4])\n",
        "    company_names_2017.append(item[0])\n",
        "    \n",
        "  elif item[1] == 1:    \n",
        "    if item[0] == 0:\n",
        "      stock_prices_2018_c0.append(item[4])\n",
        "    if item[0] == 1:\n",
        "      stock_prices_2018_c1.append(item[4])\n",
        "    if item[0] == 2:\n",
        "      stock_prices_2018_c2.append(item[4])\n",
        "    days_in_2018.append(item[2])\n",
        "    stock_prices_2018.append(item[4])\n",
        "    company_names_2018.append(item[0])\n",
        "  \n",
        "  elif item[1] == 2:\n",
        "    if item[0] == 0:\n",
        "      stock_prices_2019_c0.append(item[4])\n",
        "    if item[0] == 1:\n",
        "      stock_prices_2019_c1.append(item[4])\n",
        "    if item[0] == 2:\n",
        "      stock_prices_2019_c2.append(item[4])\n",
        "    days_in_2019.append(item[2])\n",
        "    stock_prices_2019.append(item[4])\n",
        "    company_names_2019.append(item[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMtG0eBFihFv"
      },
      "source": [
        "def plot_all_companies_stock_price_all_years(data, x_start, x_end):\n",
        "  sns.scatterplot(x=all_days, y=all_stock_prices, hue=all_company_names, palette=\"deep\")\n",
        "\n",
        "def plot_stock_year(year):\n",
        "  _day = []\n",
        "  _stock_price = []\n",
        "  _companies = []\n",
        "\n",
        "  if year == 2017:\n",
        "    _day = days_in_2017\n",
        "    _stock_price = stock_prices_2017\n",
        "    _companies = company_names_2017\n",
        "  elif year == 2018:\n",
        "    _day = days_in_2018\n",
        "    _stock_price = stock_prices_2018\n",
        "    _companies = company_names_2018\n",
        "  elif year == 2019:\n",
        "    _day = days_in_2019\n",
        "    _stock_price = stock_prices_2019\n",
        "    _companies = company_names_2019\n",
        "  plt.clf()\n",
        "  sns.scatterplot(x=_day, y=_stock_price, hue=_companies, palette=\"deep\")\n",
        "\n",
        "#plot_all_companies_stock_price_all_years(combined_data, min_day, max_day)\n",
        "plot_stock_year(2017)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z28ZnTQciif9"
      },
      "source": [
        "def plot_subplots(accuracy, losses):\n",
        "  plt.subplot(331)\n",
        "  plt.plot(stock_prices_2017_c0)\n",
        "\n",
        "  plt.subplot(332)\n",
        "  plt.plot(stock_prices_2018_c0)\n",
        "\n",
        "  plt.subplot(333)\n",
        "  plt.plot(stock_prices_2019_c0)\n",
        "\n",
        "  plt.subplot(334)\n",
        "  plt.plot(stock_prices_2017_c1)\n",
        "\n",
        "  plt.subplot(335)\n",
        "  plt.plot(stock_prices_2018_c1)\n",
        "\n",
        "  plt.subplot(336)\n",
        "  plt.plot(stock_prices_2019_c1)\n",
        "\n",
        "  plt.subplot(337)\n",
        "  plt.plot(stock_prices_2017_c2)\n",
        "\n",
        "  plt.subplot(338)\n",
        "  plt.plot(stock_prices_2018_c2)\n",
        "\n",
        "  plt.subplot(339)\n",
        "  plt.plot(stock_prices_2019_c2)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "plot_subplots(accura, losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV7R2YWZijw7"
      },
      "source": [
        "def plot_subplots2(accuracy, losses):\n",
        "  #plt.subplot(331)\n",
        "  #plt.plot(stock_prices_2017_c0)\n",
        "  \n",
        "  ### Company 1\n",
        "  fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "  fig.tight_layout(pad=3)\n",
        "  ax1.plot(stock_prices_2017_c0)\n",
        "  ax2.plot(stock_prices_2018_c0)\n",
        "  ax3.plot(stock_prices_2019_c0)\n",
        "  # Labels\n",
        "  fig.suptitle('Company 1 Stock price 2017 - 2019', fontsize = 16)\n",
        "  #x\n",
        "  ax1.set_xlabel('Days - 2017', fontsize=10)\n",
        "  ax2.set_xlabel('Days - 2018', fontsize=10)\n",
        "  ax3.set_xlabel('Days - 2019', fontsize=10)\n",
        "  #y\n",
        "  ax1.set_ylabel('Stock price', fontsize=10)\n",
        "  ax2.set_ylabel('Stock price', fontsize=10)\n",
        "  ax3.set_ylabel('Stock price', fontsize=10)\n",
        "\n",
        "  ### Company 2\n",
        "  fig2, (ax4, ax5, ax6) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "  fig2.tight_layout(pad=3)\n",
        "  ax4.plot(stock_prices_2017_c1)\n",
        "  ax5.plot(stock_prices_2018_c1)\n",
        "  ax6.plot(stock_prices_2019_c1)\n",
        "  # Labels\n",
        "  fig2.suptitle('Company 2 Stock price 2017 - 2019', fontsize = 16)\n",
        "  #x\n",
        "  ax4.set_xlabel('Days - 2017', fontsize=10)\n",
        "  ax5.set_xlabel('Days - 2018', fontsize=10)\n",
        "  ax6.set_xlabel('Days - 2019', fontsize=10)\n",
        "  #y\n",
        "  ax4.set_ylabel('Stock price', fontsize=10)\n",
        "  ax5.set_ylabel('Stock price', fontsize=10)\n",
        "  ax6.set_ylabel('Stock price', fontsize=10)\n",
        "\n",
        "  ### Company 3\n",
        "  fig3, (ax7, ax8, ax9) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "  fig3.tight_layout(pad=3)\n",
        "  ax7.plot(stock_prices_2017_c2)\n",
        "  ax8.plot(stock_prices_2018_c2)\n",
        "  ax9.plot(stock_prices_2019_c2)\n",
        "  # Labels\n",
        "  fig3.suptitle('Company 3 Stock price 2017 - 2019', fontsize = 16)\n",
        "  #x\n",
        "  ax7.set_xlabel('Days - 2017', fontsize=10)\n",
        "  ax8.set_xlabel('Days - 2018', fontsize=10)\n",
        "  ax9.set_xlabel('Days - 2019', fontsize=10)  \n",
        "  #y\n",
        "  ax7.set_ylabel('Stock price', fontsize=10)\n",
        "  ax8.set_ylabel('Stock price', fontsize=10)\n",
        "  ax9.set_ylabel('Stock price', fontsize=10)\n",
        "\n",
        "  plt.show();\n",
        "\n",
        "plot_subplots2(accura, losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnVecd3AilM0"
      },
      "source": [
        "accuracies_e1_e2 = {\n",
        "    \"expert1\": _e1_accuracy,\n",
        "    \"expert2\": _e2_accuracy\n",
        "}\n",
        "experts_accuracy_keys = accuracies_e1_e2.keys()\n",
        "experts_accuracy_values = accuracies_e1_e2.values()\n",
        "\n",
        "def plot_experts(keys, values):    \n",
        "  plt.bar(keys, values, color=[\"green\", \"red\"])\n",
        "  # Add title and axis names\n",
        "  plt.title('Experts Accuracy')\n",
        "  plt.xlabel('experts')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.show()\n",
        "  \n",
        "plot_experts(experts_accuracy_keys, experts_accuracy_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5LMnEPXimWW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}